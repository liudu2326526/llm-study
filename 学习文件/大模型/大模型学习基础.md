# 大模型基础

## 目录
1. [大模型技术概述](#1-大模型技术概述)
2. [Tuning技术](#2-tuning技术)
3. [GPT系列模型核心原理](#3-gpt系列模型核心原理)
4. [大模型核心原理（其他代表模型）](#4-大模型核心原理)

---

## 1 大模型技术概述
### 1.1 Transformer模型家族分类
| 模型类型 | 代表模型 | 核心特点 |
| --- | --- | --- |
| 序列到序列模型（encoder-decoder） | T5 | 兼顾理解与生成任务 |
| 自编码模型（encoder-only） | BERT | 双向注意力，擅长理解任务 |
| 自回归模型（decoder-only） | GPT | 单向注意力，擅长生成任务 |

### 1.2 大模型发展时间线
- 2017年：Google推出Transformer，提出“Attention is all you need”
- 2018年：OpenAI发布GPT-1（6月），Google发布BERT（10月）
- 2019年：OpenAI发布GPT-2（1.5B参数），引入zero-shot概念
- 2020年：OpenAI发布GPT-3（175B参数），达到SOTA水平
- 2022年：OpenAI发布ChatGPT（11月），开启对话式AI热潮
- 2023年：OpenAI发布GPT-4（3月），支持多模态能力
- 2024年：Meta发布Llama 3.1/3.2（7月/9月），OpenAI发布o1系列推理模型（9月），DeepSeek发布V3（12月）
- 2025年：DeepSeek发布R1推理模型（1月），开启开源模型逻辑推理新纪元

### 1.3 语言模型发展阶段
1. **Pre-training + Fine-tuning阶段**：代表模型BERT、GPT、XLNet，基于Transformer自监督预训练+任务微调
2. **规模扩大阶段**：代表模型BART、T5、GPT-3，扩大参数与训练语料规模
3. **AIGC初期阶段**：代表模型InstructionGPT、ChatGPT、GPT-4，对话式、生成式、多模态，注重人类对齐

### 1.4 主流开源大模型
- **国外**：Llama (Meta), Mistral, Gemma (Google), Claude (Anthropic, 非开源但影响大)
- **国内**：DeepSeek (深度求索), Qwen (通义千问), ChatGLM (智谱AI), Baichuan (百川智能), Yi (零一万物)

## 2 Tuning技术
### 2.1 NLP发展的四个范式
| 范式 | 核心特点 | 关键工程 |
| --- | --- | --- |
| P1（非神经网络完全监督） | 依赖人工特征工程 | 特征模板定义 |
| P2（神经网络完全监督） | 依赖网络结构设计 | 架构工程 |
| P3（预训练+精调） | 适配下游任务 | 目标函数挖掘 |
| P4（预训练+提示+预测） | 不改动模型，适配任务 | Prompt挖掘工程 |

### 2.2 Prompt-Tuning
#### 2.2.1 核心问题
- 解决Pre-trained + Finetuning的缺陷：零样本/少样本学习能力差、模型专用性导致成本高
- 缩小预训练与微调阶段的语义差异，避免头部过拟合

#### 2.2.2 本质与定义
- 本质：下游任务重构为预训练任务形式，通过模板激发模型补全能力
- 定义：在输入段添加额外文本，为预训练模型提供线索/提示的技术（提示学习）

#### 2.2.3 工作流
1. 构造Prompt模板（Template）
2. 构造答案空间映射（Verbalizer）
3. 文本代入模板，模型预测
4. 预测结果映射回label

#### 2.2.4 Template分类
- 按slot位置：Cloze（完形填空式）、Prefix（前缀式）
- 按制定方式：Discrete Template（硬模板，固定字符）、Continuous Template（软模板，参数可调）

### 2.3 Instruction-Tuning
#### 2.3.1 核心目标
通过多任务指令微调，提升模型对未见过任务的zero-shot能力

#### 2.3.2 关键实现
- 训练数据：60+ NLP任务组成的数据集，分为12个类别
- 模板设计：每个任务设计10个instruction template，随机格式化数据
- 代表模型：FLAN（137B参数），在25个数据集中20个超越zero-shot GPT-3

#### 2.3.3 与Prompt-Tuning的区别
- Prompt-Tuning：激发模型补全能力，类似语言模型任务
- Instruction-Tuning：激发模型理解能力，通过指令让模型做出对应动作，是Finetune与Prompt的结合

## 3 GPT系列模型核心原理
### 3.1 GPT系列基础信息
| 模型 | 发布时间 | 参数量 | 预训练数据量 | 核心关键词 |
| --- | --- | --- | --- | --- |
| GPT-1 | 2018.6 | 1.17亿 | 约5GB | 自回归、生成式、预训练+微调 |
| GPT-2 | 2019.2 | 15亿 | 40GB | 去除fine-tune、zero-shot、提示驱动 |
| GPT-3 | 2020.5 | 1750亿 | 45TB | in-context learning、few-shot |
| InstructGPT | 2022.1 | - | - | RLHF、对齐人类指令 |
| GPT-4 | 2023.3 | - | - | 多模态、多模态、更强逻辑推理 |
| GPT-4o | 2024.5 | - | - | 实时多模态、全能模型 |
| OpenAI o1 | 2024.9 | - | - | 强化学习、思维链推理、解决复杂STEM问题 |

### 3.2 GPT-1核心原理
#### 3.2.1 无监督预训练
- 数据集：BooksCorpus（7000本未发布书籍）
- 优化目标：

$$
L_{1}(\mathcal{U}) = \sum_{i} \log P(u_{i} \mid u_{i-k}, \dots, u_{i-1}; \Theta)
$$
- 模型结构：12个Transformer decoder block

#### 3.2.2 有监督微调
- 任务类型：分类、文本蕴含、相似性、多选题
- 优化目标：

$$
L_{3}(\mathcal{C}) = L_{2}(\mathcal{C}) + \lambda \times L_{1}(\mathcal{C})
$$
- 参数说明：$\lambda$ 为超参数，默认值为 0.5。
- 训练策略：仅训练输出层 $W_{y}$ 和分隔符 Embedding。

### 3.3 GPT-2核心改进
- 模型调整：LayerNorm位置优化、扩展词汇表到50257、上下文大小到1024
- 数据集：WebText（800万文本，40GB），移除Wikipedia内容
- 核心能力：无需微调，通过提示完成多任务zero-shot推理

### 3.4 GPT-3核心创新
#### 3.4.1 in-context learning
- 三种任务形式：
  - zero-shot：仅提供任务描述
  - one-shot：任务描述+1个示例
  - few-shot：任务描述+多个示例
- 无需梯度更新，直接使用预训练模型预测

#### 3.4.2 模型调整
- 单词embedding大小从1600增至12888，上下文窗口从1024增至2048
- 采用dense and locally banded sparse attention结构
- 参数量级达175B，支持更大批量训练（3.2M tokens）

### 3.5 InstructGPT核心优化
#### 3.5.1 对齐目标
helpful（辅助任务）、honest（不编造信息）、harmless（无伤害）

#### 3.5.2 RLHF训练流程
1. 有监督微调（SFT）：收集标注数据微调模型
2. 奖励模型训练（RM）：收集对比数据训练奖励模型
3. 强化学习对齐：基于PPO算法通过RM优化模型

### 3.6 GPT-4关键特性
- 多模态支持：文本+图像输入
- 性能表现：在学术考试（律师资格考试、LSAT等）中表现优异
- 局限性：知识截止2021.9、存在推理错误、生成内容非绝对可靠

### 3.7 OpenAI o1 系列 (推理模型)
#### 3.7.1 核心理念：慢思考
- **System 2 思维**：不同于以往模型的“快思考”（预测下一个 token），o1 通过强化学习训练，在输出前进行长时思维链（CoT）推理。
- **思维链隐藏**：模型内部进行推理，仅展示最终结果，提升了安全性与推理质量。

#### 3.7.2 关键优势
- **复杂推理**：在数学（AIME）、编程（Codeforces）和科学问题上显著超越 GPT-4o。
- **自我纠错**：在推理过程中能够识别并修正自身的错误。

#### 3.7.3 模型矩阵
- **o1-preview**：系列首个预览版，展示强大推理能力。
- **o1-mini**：针对编程和 STEM 优化的轻量级模型，速度快、成本低。
- **o1**：完全体模型，具备更广博的知识和更强的综合能力。

## 4 大模型核心原理
### 4.1 BLOOM
#### 4.1.1 基础信息
- 参数量：1760亿，支持46种自然语言+13种编程语言
- 训练数据：ROOTS语料（1.61TB），含OSCAR、GitHub代码等
- 训练环境：Jean Zay超级计算机（384张A100 GPU），训练时长3.5个月

#### 4.1.2 核心技术
- 位置编码：ALIBI（旋转位置编码变体，提升长度外推性）
- Tokenization：BPE算法，词表大小250680，支持多语言无损编码
- 并行策略：3D并行（DP+PP+TP），基于Megatron-DeepSpeed框架

### 4.2 LLaMA系列
#### 4.2.1 LLaMA-1
- 参数量：7B/13B/33B/65B，训练数据1.4T tokens
- 核心技术：Pre-Normalization（RMSNorm）、SwiGLU激活函数、RoPE位置编码
- 性能：LLaMA-13B优于GPT-3（175B），LLaMA-65B接近Chinchilla-70B

#### 4.2.2 LLaMA-2
- 改进：训练数据增加40%，上下文长度从2048增至4096
- 版本：7B/13B/70B，Chat版本经过10万SFT数据+100万人类偏好数据训练
- 局限性：中文占比仅0.13%，中文支持较差

#### 4.2.3 LLaMA-3 / 3.1 / 3.2
- **LLaMA-3**：8B/70B，词表 128K，上下文 8K。
- **LLaMA-3.1**：
  - **规模**：增加 405B 超大规模版本，可与 GPT-4o 竞争。
  - **改进**：全系列支持 128K 上下文，支持 8 种语言（含德、法、意、葡、印、西、泰）。
  - **能力**：显著提升了工具使用、长文本摘要和复杂推理能力。
- **LLaMA-3.2**：
  - **多模态**：推出 11B 和 90B 的视觉模型，支持图像理解。
  - **轻量化**：推出 1B 和 3B 纯文本模型，专为移动端边缘设备优化。

### 4.3 Baichuan系列
#### 4.3.1 Baichuan-7B
- 参数量：70亿，训练数据1.2万亿tokens，上下文长度4096
- 特性：支持中英双语，宽松开源协议（允许商业使用）
- 技术：RoPE位置编码、SwiGLU激活函数、RMSNorm预归一化

#### 4.3.2 Baichuan2
- 参数量：7B/13B（Base/Chat版本），训练数据2.6万亿tokens
- 技术：7B用RoPE，13B用ALiBi，xFormers内存高效注意力
- 性能：在C-Eval、MMLU等基准测试中位列同尺寸模型前列

### 4.4 ChatGLM系列
#### 4.4.1 核心架构
- 基于GLM架构，融合单向/双向注意力机制，统一理解与生成任务
- 预训练任务：Autoregressive Blank Infilling（自回归空格填充）

#### 4.4.2 系列演进
| 模型 | 参数量 | 上下文长度 | 核心改进 |
| --- | --- | --- | --- |
| ChatGLM-6B | 62亿 | 2K | 量化部署，支持消费级显卡 |
| ChatGLM2-6B | 62亿 | 32K | FlashAttention技术，推理速度提升42% |
| ChatGLM3-6B | 62亿 | 32K | 支持工具调用、代码执行，多场景适配 |

#### 4.4.3 性能优势
- 中文任务：CLUE、FewCLUE基准超越ERNIE3.0、Yuan等模型
- 英文任务：MMLU、LAMBADA等基准超越GPT-3、OPT等模型

### 4.5 DeepSeek 系列
#### 4.5.1 DeepSeek-V3
- **架构创新**：
  - **MLA (Multi-head Latent Attention)**：大幅压缩 KV Cache 占用，提升推理吞吐。
  - **DeepSeekMoE**：671B 总参数，每 token 激活 37B，采用无辅助损失的负载均衡策略。
  - **MTP (Multi-Token Prediction)**：预测未来多个 token，增强模型表征能力。
- **训练效率**：采用 FP8 混合精度训练，大幅降低训练成本和显存占用。

#### 4.5.2 DeepSeek-R1 (推理模型)
- **训练算法**：采用 **GRPO (Group Relative Policy Optimization)**，无需传统 RLHF 中的 Critic 网络，直接基于规则奖励进行大规模强化学习。
- **发展路径**：
  - **R1-Zero**：纯 RL 训练，涌现出“Aha Moment”（自我反思与验证）。
  - **R1**：在 RL 基础上加入少量冷启动 SFT 数据，解决了语言混杂和排版问题。
- **知识蒸馏**：将 R1 的推理能力蒸馏至 Llama 和 Qwen 等小模型中（1.5B - 70B）。

### 4.6 Qwen 系列 (通义千问)
#### 4.6.1 Qwen 2.5
- **全面升级**：预训练数据量达 18T tokens，全系列在代码、数学和多语言能力上显著提升。
- **专家模型**：
  - **Qwen2.5-Coder**：在多个编程榜单上超越或接近 GPT-4o 性能。
  - **Qwen2.5-Math**：强化了复杂数学题解题能力。
- **Qwen2.5-Max**：大规模 MoE 模型，性能对标 GPT-4o 和 DeepSeek-V3。