# 刘度 - 大数据开发工程师个人简历
## 基本信息
|项目|详情|
| ---- | ---- |
|姓名|刘度|
|年龄|29岁|
|电话|13380365400（微信同号）|
|邮箱|liudu2326526@163.com|
|住址|广东省深圳市宝安区|
|工作经验|8年|
|工作状态|在职|
|入职时间|一个月内|
|毕业院校|四川大学|
|学历|本科|
|求职意向|大数据开发工程师|

## 工作经历
1. **2022.09 - 至今**：东信时代信息技术有限公司，数据组长（4人团队）
2. **2020.09 - 2022.08**：大宇无限科技有限公司，高级大数据开发工程师
3. **2017.06 - 2020.08**：济南铭函通信技术有限公司，大数据开发工程师

## 职业技能
### 大模型与 Agent 应用
*   **Agent 架构与开发**：深入理解 **AI Agent** 核心逻辑（LLM + Planning + Memory + Tools），熟练掌握 **LangChain**、**AutoGen**、**CrewAI** 等主流框架，具备多智能体（Multi-Agent）协作系统设计与落地经验；熟悉 **ReAct**、**Plan-and-Solve** 等规划模式及 **CoT**（思维链）提示工程。
*   **RAG 检索增强生成**：精通 **RAG** 技术架构，熟悉向量数据库（**Milvus**、**Chroma**、**Faiss**）及 Embedding 模型调优，掌握文档切片（Chunking）、混合检索（Hybrid Search）、重排序（Rerank）等提升召回准确率的核心技术。
*   **大模型应用落地**：熟悉 **Transformer** 架构与 **Prompt Engineering**，了解大模型微调（**LoRA**、**P-Tuning**）流程；具备使用 **vLLM**、**Ollama** 等工具进行模型私有化部署与推理加速的经验；熟悉 **MCP**（Model Context Protocol）协议及工具调用（Function Calling）；
*   **训练数据清洗加工**：熟悉大模型训练数据处理流程，掌握数据清洗（Data Cleaning）、去重（De-duplication）、格式化（Formatting）及指令微调数据集构建。

### 大数据架构与开发
*   **数据架构与建模**：精通 **Kimball** 维度建模理论，具备 PB 级离线/实时数仓从 0 到 1 的建设经验；熟悉数据治理体系，主导过数据质量（DQC）、元数据管理、数据血缘及开发规范的制定与落地。
*   **数据分析与挖掘**：熟悉用户生命周期模型（AARRR），具备用户画像及指标体系搭建经验；掌握数据挖掘算法（回归、聚类），能通过 A/B Test 及数据分析工具（Pandas/Numpy）深入挖掘数据价值，驱动业务决策。
*   **计算与存储引擎**：精通 **Spark**（SQL调优/AQE）、**Flink**（DataStream/CDC/Exactly-once）计算引擎；熟悉 **Hadoop** 生态（HDFS/Yarn）；熟练使用 **Doris**、**StarRocks**、**Hudi** 构建实时湖仓；掌握 **Kafka**、**Redis**、**HBase** 等存储组件。
*   **开发与工具**：熟练使用 **Java/Python/Shell** 进行数据开发；熟悉 Linux 系统管理及 JVM 调优；具备 **QuickBI**、**Impala**、**Presto** 等工具使用经验。
*   **项目管理**：持有公司认证的 **PMP** 证书，具备技术团队管理、方案设计及跨部门协作经验。

## 项目经历

### 项目一：AI营销全栈智能体平台（Agent Platform）
**项目架构**：FastAPI + LangGraph + MySQL + ES + Redis + Neo4j + Celery + 华为云 OBS
**项目描述**：面向企业级营销场景构建的 Agent 全栈平台，旨在实现从营销策划、素材生产到投放分析的全链路自动化。系统基于 **LangGraph** 构建高度灵活的智能体编排引擎，支持单智能体（Solo）及多智能体团队（Team）的复杂任务协同。通过自研的上下文与记忆引擎（Context Engine），实现了 USER-PROJECT-TASK 三级作用域的知识检索与状态保持，支持营销领域知识图谱的深度集成。

**职责描述**：
1. **核心引擎开发**：基于 **LangGraph** 实现 AgentLoop 闭环引擎（Plan -> Act -> Reflect -> Eval），支持任务状态的持久化、暂停与恢复，解决了长路径任务执行中的状态丢失问题；
2. **多模态能力集成**：设计并实现媒体生成网关，支持模型输出中嵌套媒体任务指令（<<MEDIA_TASK>>），自动调度异步生成视频（Seedance）与图片（Seedream），实现“边聊边画/剪”的交互体验；
3. **上下文与记忆管理**：研发分层记忆引擎，通过 **Redis** 管理短期记忆，**ES + Neo4j** 构建多源混合检索（RAG），实现了基于用户偏好、项目背景与任务上下文的精准知识注入；
4. **资产管理体系**：构建营销素材库（Asset Hub），实现多模态素材的异步特征提取、版本控制与生成谱系（Lineage）追踪，确保内容生产的可追溯性；
5. **系统架构优化**：采用 **FastAPI** 异步架构，通过 SSE 实现 Agent 执行过程的流式实时输出，集成 **OpenTelemetry** 实现全链路 Trace 监控，确保系统高并发下的可观测性。

**项目成果**：
1. 成功交付 MVP 版本，支撑了营销策划与多模态素材生成的闭环流程，Agent 任务执行成功率提升至 85% 以上；
2. 实现了毫秒级的知识召回响应，通过混合检索策略将 Prompt 上下文的精准度提升了 40%，显著减少了模型幻觉；
3. 建立了标准化的 Agent 开发规范与组件库，支持新业务 Agent 的快速接入，开发周期缩短 50%；
4. 系统架构具备良好的横向扩展性，支持多模型（GPT/Claude/DeepSeek/豆包）动态路由与负载均衡。

### 项目二：AI智能视频剪辑平台（AI Agent应用）
**项目架构**：FastAPI + Celery + Redis + ES + LangChain + FFmpeg + OpenAI/Claude
**项目描述**：针对短视频生产效率低、素材复用难的痛点，自主研发的全流程AI视频创作平台。系统基于 **Multi-Agent** 架构，实现了从素材上传、智能理解、切片入库到创意脚本生成、素材自动匹配及最终视频合成的端到端自动化。通过构建垂直领域的 **RAG**（检索增强生成）系统，解决了非结构化视频数据的语义检索难题，大幅降低了视频制作门槛与成本。

**职责描述**：
1. **架构设计**：主导后端整体架构设计，采用 **FastAPI** 构建高性能 API 服务，结合 **Celery + Redis** 实现复杂的异步任务编排与状态管理，确保长链路视频处理任务的稳定性；
2. **Agent框架开发**：设计并实现通用的 **BaseAgent** 框架，规范了 LLM 交互、Prompt 管理、结构化输出解析（JSON）及错误重试机制，支撑了视频理解、剧本生成、剪辑等多个子 Agent 的快速开发；
3. **素材智能化处理**：开发 **VideoUnderstandingAgent** 与 **MaterialSlicingAgent**，集成 **FFprobe** 与视觉模型，实现视频素材的自动打标、场景切片与评分，构建了高质量的视频向量数据库（**ES**）；
4. **创意生成系统**：研发 **ScriptWriterAgent**，基于 LLM 自动生成分镜脚本与 TTS 配音；设计 **MatchingAgent** 实现“剧本-素材”的语义匹配，采用“召回+精排”策略提升素材匹配准确率；
5. **自动化剪辑合成**：开发 **RenderingAgent** 与 **RoughCutAgent**，将创意脚本转化为 **FFmpeg** 编辑指令，自动合成含字幕（ASS）、配音与转场的成片；
6. **工程化落地**：规范代码结构与开发流程，编写核心设计文档（AGENTS.md），统一异常处理与日志监控，提升系统可维护性。

**项目成果**：
1. 成功构建了一套可扩展的 **AI Agent** 视频生产系统，实现了素材处理与视频辑的 **100% 自动化**，单视频制作周期从小时级缩短至分钟级；
2. 搭建了基于 **ES** 的多模态 **RAG** 检索系统，实现了自然语言对视频片段的精准检索，素材复用率提升 **300%**；
3. 通过 **Celery** 异步编排实现了多 Agent 协同工作（理解->脚本->匹配->剪辑），支持高并发任务处理，系统吞吐量显著提升；
4. 沉淀了一套完整的 Agent 开发规范与工具链，为后续引入精细化剪辑（FineCut）与脚本校验（Validator）奠定了坚实基础。

### 项目三：AI智能营销素材生成平台（AI Agent应用）
**项目架构**：FastAPI + MongoDB + LangChain + Langfuse + Volcengine(Jimeng) + DeepSeek + Redis
**项目描述**：面向智能营销场景的AIGC生产平台，旨在解决营销素材（图片、文案、分镜）生产成本高、创意枯竭的问题。系统采用 **FastAPI** 构建，基于 **MongoDB** 实现自定义的分布式任务调度系统（Scheduler），集成了 **LangChain** 与 **DeepSeek** 大模型，实现了从创意裂变、提示词优化到多模型（即梦、火山、NanoBanana）图像生成的全链路自动化。引入 **Langfuse** 实现全链路监控与评估。

**职责描述**：
1. **架构设计**：主导后端整体架构设计，构建基于 **MongoDB** 的“生产者-消费者”任务调度系统（Scheduler），通过 `Splitter` 拆解任务与 `Processor` 并行执行，解耦了任务提交与耗时生成逻辑，支持高并发创作请求；
2. **Agent开发**：开发核心 Agent（`HuoshanImageGenerator`, `TrendingImageGenerator`），封装了火山引擎、即梦等多个下游生图模型接口，实现了“文生图”、“图生图”及“爆款仿图”等核心功能；
3. **Prompt工程**：基于 **LangChain** 设计提示词优化 Agent (`PromptGeneratorAgent`)，利用 LLM 对用户简略输入进行扩写与优化，大幅提升了生成素材的质量与准确性；
4. **全链路监控**：集成 **Langfuse** 追踪平台，对 Agent 的每一次 LLM 调用与工具执行进行 Trace 记录，实现了 Token 消耗统计、延迟分析及生成质量的在线评估；
5. **系统稳定性**：设计完善的错误重试与状态流转机制，确保在外部 API（如火山引擎）波动时任务状态的一致性，保障了 7x24 小时的服务稳定性。

**项目成果**：
1. 成功上线并支撑了日均数千次的营销素材生成任务，将单张营销图的设计周期从小时级降低至秒级；
2. 构建了支持多模型（Jimeng/Huoshan/NanoBanana）切换的生图引擎，通过配置化调度实现了模型资源的动态分配与成本优化；
3. 实现了基于 **Langfuse** 的精细化运营，通过 Trace 数据分析持续优化 Prompt 模板，素材生成可用率提升至 90% 以上；
4. 打造了“创意裂变”与“爆款复刻”等特色功能，显著提升了营销投放的转化率（CTR）。

### 项目四：营赛洞察SaaS数据中台建设（数仓建设）
**项目架构**：Spark+Flink+Doris+华为云DLI(Hive)+华为云DataArts+Hudi+Kafka+matebase
**项目描述**：营赛洞察是东信时代的大数据SaaS产品，初期存在数据架构设计不合理、缺乏数据规范等问题，导致用户取数成本高、新指标开发耗时长、旧代码维护成本高、机器费用无序扩展。主导数仓架构升级，通过维度建模和业务域划分整合7大业务域（品牌、主体、商品、品类、活动、热点、KOL）解决数据孤岛问题；建设标准化报表体系提升数据应用效率；实现数据基建、数据资产、数据服务、数据应用的全链路改造升级。

**职责描述**：
1. 梳理业务场景，牵头完成数据指标梳理并构建指标体系，实现统一管理；
2. 负责大数据平台规划、架构设计及实施落地，为数据全流程提供架构支撑；
3. 设计、建模并持续改进数仓，利用维度建模构建高内聚、低耦合的数仓模型；
4. 建立数据开发规范，规范团队开发工作，保障代码提交质量；
5. 制定数据质量保障方案(SLA 监控)，保障公共层数据的及时性、稳定性和准确性；
6. 持续优化大数据平台离线、实时数据处理程序及架构，提升性能；
7. 预研大数据架构新技术并分析应用可行性；
8. 负责大数据团队的日常管理工作。

**项目成果**：
1. 作为数据组对外接口人，完成业务需求沟通与业务模型建设，构建标准化数仓，下线40+无用/临时数据表，整合20+应用层烟囱数据表，ODS穿透率从23%降至4%；
2. 制定设计规范与统一术语，完成数仓mapping建设和总线矩阵构建，优化100+烟囱式开发及高消耗任务，数据产出时效提前1小时；
3. 用Spark sql处理离线数据并完成Spark优化与版本升级至3.0，开启AQE实现任务自动优化，提升开发效率；
4. 基于Flink实现实时计算，完成事件表与维度表实时join，通过相关配置保证数据精准一次性消费，削峰填谷降低算法处理成本80%；
5. 引入Doris构建实时数仓，实现上百QPS查询并发和秒级查询速度，将定向监测模块时效性从小时级提升至分钟级；
6. 引入Hudi和华为云serverless服务，降低计算和存储成本约30%；
7. 通过metabase搭建自研OLAP分析系统，输出统一分析口径，节省数据开发导数时间。

### 项目五：营赛洞察SaaS数据治理平台（数据治理）
**项目架构**：Spark+Flink+华为云DLI(Hive)+华为云DataArts+python+shell
**项目描述**：随着业务发展，营赛洞察指标增多，数据分散、低质量、规范性和安全问题阻碍数据价值发掘。成立数据治理委员会，初期落实数据规范、提升数据质量、保障数据安全，解决数据孤岛；后期加强元数据管理，补齐数据属性信息，降低使用成本，打造标准化、安全可控、持续增值的数据资产。

**职责描述**：
1. 主导数据治理体系设计，搭建元数据管理平台及数据价值评价模型，实现元数据自动化采集与血缘分析；
2. 设计并开发实时数据质量监控系统，构建覆盖表级/字段级的6大质量维度监控体系；
3. 构建自动化检测任务，结合脚本、DQC工具减少人工干预；
4. 建立数据质量问题库，定期输出质量报告，集中管理历史问题；
5. 制定大数据任务管理规范及应急响应流程，确保异常及时解决；
6. 制定值班制度，明确表的分级，在保障数据产出的同时降低维护成本。

**项目成果**：
1. 构建标准化数据治理流程，明确各职能团队分工，提升组织协作效率；
2. 通过Python+Shell脚本集成华为云DataArts API，实现检测模板自动生成和质量规则库动态加载，企业微信告警，监控覆盖1000+数据表；
3. 梳理指标体系框架，定义原子/衍生指标，与产品经理共建指标体系，整合7大数据资产并实现标签及模型统一收口；
4. 制定数据开发SOP规范，设计P0/P1/P2分级保障机制，建立分钟级应急响应体系，关键任务SLA达标率提升至99.9%；
5. 打造全链路质量保障体系，实现核心数据资产100% DQC监控覆盖，建设7条基线保障机制，数据及时率从85%提升至99.7%，故障恢复时效缩短至30分钟；
6. 制定异常处理手册和值班规范，实现数据异常下游链路阻断与人工干预，问题平均响应时间从12小时缩短至1小时；
7. 管理数据质量问题，沉淀200+质量问题案例库，推动业务反馈量同比下降90%，数据信任度提升40%。

### 项目六：定向实时舆情监测系统（实时数仓）
**项目架构**：Flink+Kafka+Doris+Mysql+K8S+StreamPark+prometheus+grafana
**项目描述**：为赋能客户精准捕捉产品市场动态与投放活动即时反馈打造该系统，集成实时数据采集、情感分析、分词标注等算法，助力客户从多维度剖析品牌表现，实现市场响应即时化与精准化。

**职责描述**：
1. 负责项目规划与管理，全程把控立项到交付，定期组织周会，管理风险并协调多部门协同；
2. 主导前期可行性研究与方案设计，构建以Flink+Kafka+Doris为核心的高性能实时处理架构；
3. 研究并实践Flink on K8S部署方案，定制Flink镜像，依托华为云提升系统部署灵活性与可扩展性；
4. 开发核心数据流，实现发文、作者、评论、活动信息的深度关联与宽表加工；
5. 搭建StreamPark实时任务处理平台，维护任务运行并持续优化。

**项目成果**：
1. 采用K8S部署策略，降低服务器扩容与部署成本，依托其高可用特性保障任务稳定运行；
2. 运用Flink的Interval join和lookup join提升数据关联性能，通过Flink调优提升任务吞吐量；
3. 基于StreamPark搭建的平台实现60+实时任务全生命周期监控，集成双通道告警，任务异常恢复时效缩短至5分钟；
4. 通过prometheus + grafana实现30+ Kafka topic监控报警，数据丢失率降至0.01%；
5. 系统关键指标（舆情预警、情感分析）产出延迟从小时级压缩至20秒内，支撑客户营销策略调整效率提升5倍。

### 项目六：营赛洞见大模型（大模型知识库）
**项目架构**：FastAPI+SSE+华为云DLI+ES+Langchain
**项目描述**：面向智能营销场景的行业级大模型解决方案，集成LLM微调（LoRA）、RAG增强检索、多模态知识图谱（覆盖图文/视频3类媒介）等核心技术，支持12项核心业务场景，通过AI提升企业营销决策效率。

**职责描述**：
1. 构建模型服务，参考Langchain打通知识库、实时检索、Text2API等服务并上线维护；
2. 构建并优化知识库服务，通过多模态数据向量化技术实现数据与行业知识的高效关联与检索，优化数据结构与查询算法；
3. 构建内容审核模块，过滤不合规范的问答与回答；
4. 准备训练数据，为模型预训、微调、知识库提供数据支撑。

**项目成果**：
1. 通过多种技术屏蔽不当内容，助力模型通过信通院评测并成功上线；
2. 利用MinHash-LSH去重，通过规则和模型过滤低质量内容，确保合规性；
3. 通过多种手段完成品牌、品类、商品、景点4类知识的注入训练，知识完整度达85%；
4. 构建风控、爆文、品牌及图、文、视频三大知识库，支撑模型日常推理与风控工作。

### 项目七：大宇无限数据管理平台（数据平台）
**项目架构**：Athena+BigQuery+StarRocks+Flink+Hive+Superset
**项目描述**：旨在替换原有神策服务，基于Kimball建模理论构建数据仓库实现数据标准化管理，利用Flink做实时数据处理、Spark做离线处理，StarRocks实时摄取Kafka数据生成实时指标，通过Hudi和S3构建数据湖，Athena查询数据湖数据，Superset做数据可视化，基于AWS实现资源动态伸缩，支持大规模数据处理与分析。

**职责描述**：
1. 优化离线、实时数据处理与指标，保障数据的实时性与准确性；
2. 利用Flink CDC + Kafka框架实现10+数据源的无缝接入；
3. 搭建并优化StarRocks集群，基于其构建OLAP数据分析体系；
4. 搭建广告领域数据仓库，提供上百个高可靠业务指标，支撑多部门需求；
5. 利用Superset集成多数据源构建可视化平台，为多部门提供数据服务。

**项目成果**：
1. 参与数仓建模，采用Lambda架构和五层设计，运用星座模型做维度建模，模型落地多业务线并支撑业务决策；
2. 设计并落地公司实时数仓架构，实现实时数据处理与可视化；
3. 优化StarRocks分布式集群，将复杂查询响应时间从10秒优化至0.8秒；
4. 数据中台支持千万DAU用户及超百亿数据量，为多部门提供高可靠服务，提升查询速度并降低机器使用与维护成本。

## 自我评价
1. 具备良好的成本管理意识，能在成本消耗与项目目标间找到平衡点；
2. 拥有出色的沟通技巧，能快速、准确把握业务方的需求和意图；
3. 工作热情积极，乐于参与讨论并提出建设性意见；
4. 面对新技术和新挑战保持开放心态，乐于学习与探索；
5. 工作认真负责，确保在规定时间内高质量完成上级交办的任务；
6. 具备良好的团队合作精神，能有效组织协调团队资源，推动项目顺利开展。