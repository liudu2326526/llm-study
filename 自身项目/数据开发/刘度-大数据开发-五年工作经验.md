# 大数据开发工程师-刘度
## 个人概况
- 姓名：刘度
- 学校：四川大学
- 专业：核工程与核技术
- 学历：本科
- 邮箱：liudu2326526@163.com
- 工作经验：5年
- 联系方式：13380365400

## 工作经历
### 2020.09-至今 大宇无限科技有限公司 Data部门
**岗位**：Bigdata Engineer
**工作职责**：负责公司整体基础架构以及数仓的建设，包括底层数据的接入，OLAP 数据库的搭建，整体数仓的搭建以及配套的数据治理模块的开发

### 2017.06-2020.08 济南铭函通信技术有限公司 研发部
**岗位**：大数据开发工程师
**工作职责**：参与公司数据中台的搭建，并负责实时部分相关的链路以及指标的开发

## 专业技能描述
### 编程语言
- 熟悉JAVA 编程语言，具备良好的面向对象编程思想，熟悉JVM 的内存模型，熟悉垃圾回收流程，具备JVM 性能调优经验；
- 熟悉Vim 编辑器的常用命令，熟悉Shell 脚本的书写和使用，具备分析日志和排查问题的经验；
- 了解Python 基础以及基本使用，可以使用Python 处理数据以及编写脚本。

### 离线处理框架
- 熟悉Hadoop 基础架构以及相关组件，了解HDFS 读写流程、MapReduce 的核心编程思想和Shuffle 过程和相关优化以及Yarn 的基本组成和调度原理；
- 熟悉Hive 的组成，能熟练使用Hql 语句、系统函数以及自定义UDF，UDTF 函数来查询相关指标数据。熟悉Hive 基本优化和解决数据倾斜；
- 熟悉Spark 基本架构，及Spark 作业提交流程和相关的提交参数。理解RDD 数据集设计模式以及血缘关系。熟悉SparkStreaming 使用原理，具备Spark 调优经验。

### 实时处理框架
- 熟悉Flink 的工作原理、时间语义、watermark、算子状态，可以通过Flink 解决数据的乱序、迟到问题，以及实现精准一次性消费。能灵活使用Flink sql、算子、算子状态、定时器、对数据流进行处理；
- 熟悉Kafka 框架结构、分区分配策略、副本同步机制、Ack、幂等性、事务性。并且能根据数据流量灵活配置Kafka 的集群参数，灵活扩展Kafka 集群；
- 熟悉Hudi 的设计原则，COW 和MOR 两种表的使用，数据的写入流程，能根据不同的导入场景对参数进行调优。

### 数据库
- 熟悉StarRocks(DorisDB)的整体架构，数据读写流程，存储模型。使用routine load 实时摄取数据，建立物化视图加速查询，有大规模数据应用以及性能调优经验；
- 熟悉Hbase 的逻辑结构、读写流程、RowKey 以及预分区。并且整合了Phonenix，实现了使用SQL 对Hbase 进行操作，以及支持Hbase 建立二级索引；
- 了解Druid 的工作原理，能通过Druid 构建相应的事实指标；
- 了解MySQL 索引的建立、JDBC 操作，能灵活使用sql 对数据库中的数据进行分析。

### ETL 开发工具
- 熟悉AWS 云服务，熟悉S3、EMR、Athena、DynamoDB 的使用方法以及调优；
- 熟练使用IDEA、gitlab、maven 等开发工具；
- 了解Prometheus、Grafana 等相关监控组件；
- 了解Jenkins、Argo 复杂任务系统的使用方法；
- 了解Kubernetes 以及Docker 的原理以及使用方法。

## 项目经验
### 项目一：基于lambda 架构的大宇无限数据中台
**项目描述**：为了替换原有的神策服务，大宇无限搭建了自己的数据中台，实现对神策功能的迁移，依照kimball 建模的理论搭建了规范化的数仓。通过Flink 完成数据的实时处理与落盘，通过spark 完成对数据的离线处理，通过StarRocks 实时摄入kafka 中的数据，并生产出实时指标，通过Hudi 以及S3 构建了数据湖的存储，通过Athena 查询数据湖中的数据，并通过Superset 搭建了BI 分析工具，基于AWS 实现了资源的动态伸缩。数据中台承载千万DAU 用户的超百亿数据，并为运营、产品、算法等部门提供高可靠的数据服务。

**项目职责**：
1. 负责实时和离线数仓的建设，整体数据分层的规划，以及数仓规则的制定，将数仓分为ODS、DWD、DWS、DIM、DM 四层，规范了数据清洗流程，并收拢了全公司的指标口径。
2. 负责事件表的接入。基于Flink sql，将用户日志以及服务端日志直接接入数仓的ODS 层，并根据存储时间将数据分为冷、温、热三种不同类型的数据，采用不同的压缩方式进行存储，并使用Spark 对数据进行小文件合并。
3. 负责事实数据的处理，使用Flink 完成事件表和维度表的实时join，将事件表打宽后写入kafka 中，通过在Flink 中设置checkpoint、exactly-once 以及开启kafka的事务性保证数据的精准一次性消费。
4. 负责搭建StarRocks 集群，并基于StarRocks 开发了对实时性以及响应速度要求更高的实时指标，使用routine load 将kafka 中的数据摄取到StarRocks 中。通过合理的表设计以及物化视图，为后台服务提供上百QPS 查询并发，以及秒级别的查询速度。
5. 负责维度表的接入。对于后端数据库中的数据，使用Flink cdc 从Mysql 获取变更数据流，并同步到Hudi 表中。对于用户维表，使用OverwriteNonDefaultsWithLatestAvroPayload 实现了单个字段的维表更新。
6. 使用Spark sql 对离线数据进行处理，并且对Spark 进行了优化，合理设置spark 的excuter 数量、核数、partition 数以及内存，并且将Spark 升级到了3.0，通过开启AQE 实现了对任务的自动优化，提升开发人员的效率。
7. 使用Superset 集成Athena、StarRocks、Mysql 搭建了BI 平台，并负责广告方面的数据仓库搭建，产出上百个指标，为运营、产品、算法等部门提供高可靠的服务。
8. 基于AWS 的S3、EKS、Athena 等组建，构建了云原生的数据中台服务，使平台资源具备可扩展性，相较搭建自建集群节省了近50% 的成本。

### 项目二：大宇无限特征平台
**项目描述**：为了统一公司的特征口径，将算法老师从数据处理的工作中解放出来，本系统参照开源的特征平台feast 的设计，通过Spark 加工离线feature，Flink 加工实时特征，并将数据写入DynamoDB 为AI 的线上预估的服务提供特征输入。通过Spark 离线拼接的方式将entity 和feature 拼接起来，为AI 模型训练提供训练数据。同时开发了配套的指标观测、A/B 测等服务，为算法老师提供更科学的决策、更快速的迭代。平台减少了算法老师60% 的工作量，并使特征的口径得到了统一的管理，并且能承载100+并发的实验，每周新增实验可以达到20+。

**项目职责**：
1. 参与特征平台整体的设计，参照feast 将数据分为entity 和feature，并将整体分为了离线训练数据和线上预测数据两个模块，明确了和算法以及后台系统的交接边界。
2. 负责训练数据的生产，对于离线的特征，通过point-in-time correct join 的方式将entity 和feature 数据拼接起来生产训练数据。对于在线特征，则通过服务段数据落盘的方式将数据存储下来，通过请求ID 将特征拼接起来，生成特征数据，避免了特征穿越。
3. 负责广告方面的特征开发，如实时用户播放序列，用户点赞次数，视频观看人数等，对于一些的特征操作，如分箱、CTR 平滑等操作实现了自定义的UDF 函数对数据进行处理。并且将数据写入DynamoDB 为线上预测提供服务。
4. 负责下发和回收实验id，在下发之前通过重复shuffle 消除用户之间的差异，再给用户标记上实验id ，并推送给后端系统，并且在数据回收的落盘的Flink 程序中嵌入实验分流的SDK，数据端为用户标记上实验id。
5. 开发数据观测指标，如总VV、CTR、CVR、eCPM 等，使得实验结果可量化。

### 项目三：大宇无限数据管理平台
**项目描述**：为了方便数据工程师以及产品对数据资产进行管理，大宇无限搭建了自己的数据管理平台，管理了Athena、BigQuery、StarRocks 多个数据源的数据，并开发了数据地图、指标口径、维度字典、数据质量、权限管理等模块，实现了全公司数据产品业务指标的统一，消除了相似指标重复开发的情况，需求交付时间缩短50%，任务运维的时间缩短了80%，数据质量BUG 数下降60%。

**项目职责**：
1. 负责开发数据地图模块，集成了Glue、BigQuery 、StarRocks 的API，实现表的元数据的展示以及管理，并对产品域、主题域、分层信息、文件路径等数据进行了展示。
2. 将数据管理平台集成Superset，再通过解析SQL，实现了数据从ETL 到报表的数据血缘，降低了数据的使用成本以及问题排查的成本。
3. 基于数据地图与数据血缘开发了指标管理模块，将指标关联到对应的表和字段。基于指标规范化定义创建了原子指标和衍生指标，支持按指标名称、表示、业务口径搜索。
4. 负责开发数据质量中心，编写监控SQL 模版，对表的精准度、完整性、唯一性、一致性进行检验，还可以设置数据的同比与环比，结合企业微信机器人进行报警，实现产出的指标准确率在99% 以上。
5. 参与指定了数仓规范，并要求按流程制定规范先对表进行设计，再进行开发。通过分主题管理、规范的命名、统一指标口径、规范化开发流程，消除了重复开发，提升了开发效率，下线了20+个重复的任务，优化合并了50+个任务，节约了20% 的计算成本。