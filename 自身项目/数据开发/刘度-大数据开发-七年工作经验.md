# 刘度 - 大数据开发工程师个人简历
## 基本信息
|项目|详情|
| ---- | ---- |
|姓名|刘度|
|年龄|29岁|
|电话|13380365400（微信同号）|
|邮箱|liudu2326526@163.com|
|住址|广东省深圳市宝安区|
|工作经验|7年|
|工作状态|在职|
|入职时间|一个月内|
|毕业院校|四川大学|
|学历|本科|
|求职意向|大数据开发工程师|

## 工作经历
1. **2022.09 - 至今**：东信时代信息技术有限公司，**数据组长（7人团队）**
2. **2020.09 - 2022.08**：大宇无限科技有限公司，**高级大数据开发工程师**
3. **2017.06 - 2020.08**：济南铭函通信技术有限公司，**大数据开发工程师**

## 职业技能
### 数据建模
掌握kimball数仓维度建模理论，具备数据治理及数据质量设计经验，拥有离线、实时数仓全生命周期建设经验。

### 数据分析
熟悉指标体系、监控体系、用户画像、A/B Test平台搭建，精通用户生命周期AARRRR模型；可通过回归、聚类等算法深度分析数据，提炼核心洞察并驱动业务决策。

### 数据治理
拥有数据质量、元数据管理、数据血缘系统建设经验，主导公司数据开发规范、数仓建设规范的编写与落地执行。

### 数据采集
具备Flink CDC、Flink+Kafka、Flume、Sqoop、Maxwell/Canal等主流数据采集组件的开发与实战经验。

### 数据计算
1. 熟练编写HQL、SparkSQL脚本，精通UDF、UDAF、UDTF自定义函数开发；拥有丰富的SparkSQL调优经验，可解决各类慢SQL、数据倾斜等问题。
2. 熟练使用Flink计算引擎，具备DataStream流式处理、窗口函数、定时器、FlinkSQL开发经验；熟悉Exactly-once、CheckPoint机制，有Flink调优实战能力，可灵活运用Flink SQL、算子、算子状态、窗口处理各类数据流。

### 数据存储
1. 熟悉Hadoop体系架构，掌握HDFS、Yarn、Mapreduce等组件使用；了解Yarn任务提交、MR任务运行等底层原理，可根据业务场景选择数据异构存储、资源调度策略及存储/压缩格式。
2. 精通Kafka框架结构、分区分配策略、副本同步机制、Ack、幂等性、事务性；可根据数据流量灵活配置集群参数、扩展Kafka集群。
3. 熟悉HBase、Doris、StarRocks等实时分析数据库的架构、存储原理及应用场景，了解数据读写流程；可通过routine load实时摄取数据、建立物化视图加速查询，具备大规模数据应用及性能调优经验。
4. 熟悉Hudi设计原则，掌握COW和MOR两种表的使用及数据写入流程，可根据不同导入场景调优参数。
5. 具备Redis使用经验，了解基本数据类型的场景运用及运行参数调优方法。

### 数据可视化
拥有QuickBI可视化工具的开发与实际使用经验。

### 查询工具
了解Impala、Presto、kylin等即席查询工具，具备实际项目应用经验。

### 脚本语言
熟悉Linux日常管理操作，掌握Linux/HDFS命令；精通Java/Python/Shell语言并用于日常数据开发，具备良好的面向对象编程思想；熟悉JVM内存模型、垃圾回收流程，拥有JVM性能调优经验。

### 管理技能
具备团队管理（项目管理、技术方案设计、成员培养）经验，持有公司PMP项目管理认证。

## 项目经历
### 项目一：营赛洞察SaaS数据中台建设（数仓建设）
**项目架构**：Spark+Flink+Doris+华为云DLI(Hive)+华为云DataArts+Hudi+Kafka+matebase
**项目描述**：营赛洞察为东信时代大数据SaaS产品，初期存在数据架构设计不合理、缺乏数据规范等问题，导致用户取数成本高、新指标开发耗时久、旧代码维护成本高、机器费用无序扩展等痛点。主导数仓架构升级，通过维度建模重新梳理数仓、划分7大业务域解决数据孤岛问题，建设标准化报表体系，实现数据全链路改造升级，挖掘数据价值并提升公司竞争力。

**职责描述**：
1. 作为数据组对外接口人，梳理业务场景、需求及指标，完成业务模型建设；
2. 制定数仓设计规范与统一术语，完成mapping建设和总线矩阵构建，评审数仓模型并完成架构选型；
3. 划分团队工作，协调组员完成数据开发，主导数据接入及部分报表开发，优化慢SQL并保障数据按时产出；
4. 通过metabase搭建自研OLAP分析系统，输出统一分析口径，支撑多维度数据分析。

**项目成果**：
1. 构建标准化数仓，下线40+无用/临时数据表，整合20+应用层烟囱数据表，ODS穿透率从23%降至4%；
2. 优化100+烟囱式开发及高消耗任务，数据产出时效提前1小时；
3. 通过动态队列伸缩和存储生命周期管理，降低计算和存储成本约30%；
4. OLAP平台实现分析师自主导数据，大幅节省数据开发人力成本。

### 项目二：营赛洞察SaaS数据治理平台（数据治理）
**项目架构**：Spark+Flink+Doris+华为云DLI(Hive)+华为云DataArts
**项目描述**：随着业务发展，营赛洞察指标持续增加，数据分散、低质量、规范性不足及安全问题阻碍数据价值发掘。牵头成立数据治理委员会，初期落实数据规范、提升数据质量、保障数据安全并解决数据孤岛；后期强化元数据管理，补齐数据属性信息，打造标准统一、安全可控、持续增值的数据资产，赋能开发与业务高效用数。

**职责描述**：
1. 定义元数据规范，管理表技术/业务/操作元数据，制定数据开发规范并严格管理表的生命周期；
2. 梳理数据需求并搭建指标体系框架，定义原子/衍生指标，与产品经理共建指标体系；
3. 梳理数据质量痛点，事前定义数据准确率、SLA等质量规则标准；
4. 搭建全链路数据质量预警监控体系，通过DQC实现表级/字段级多维度校验，制定异常处理及值班规范，搭建数据问题可视化门户；
5. 建立数据质量问题管理流程，定期分析问题并输出质量报告，搭建问题库，将数据质量与KPI考核挂钩。

**项目成果**：
1. 构建标准化数据治理全流程，明确各职能团队分工，提升组织协作效率；
2. 整合10大数据资产，实现标签及模型统一收口，规范模型内容与标签口径；
3. 0-1搭建应用数据保障链路，实现基础DQC监控全链路100%覆盖，建设7条基线+SLA，具备30分钟快恢、1小时问题定位能力；
4. 大幅提升数据问题发现与解决效率，业务方问题反馈量下降90%。

### 项目三：定向实时舆情监测系统（实时数仓）
**项目架构**：Flink+Kafka+Doris+Mysql+K8S
**项目描述**：为赋能客户精准捕捉产品市场动态、获取投放活动即时反馈打造该系统，集成实时数据采集、情感分析、分词标注等算法，助力客户从PGC内容、受众反馈、内容趋势等多维度剖析品牌表现，实现市场响应的即时化与精准化。

**职责描述**：
1. 全面负责项目规划与管理，全程把控立项至交付，组织周会、管理风险并协调多部门协同推进项目；
2. 主导前期可行性研究与方案设计，构建Flink+Kafka+Doris核心实时处理架构，实现指标秒级更新；
3. 研究并落地Flink on K8S部署方案，定制Flink镜像，依托华为云提升系统部署的灵活性与可扩展性；
4. 主导核心数据流开发，实现多维度数据深度关联与宽表加工，调优关键环节保障链路高效稳定；
5. 设计ADS层模型，通过视图聚合+物化视图加速数据产出，保障指标实时性与准确性；
6. 搭建数据质量监控体系，设计备份方案，提升系统稳定性并降低业务中断风险。

**项目成果**：
1. 系统助力公司赢得百万级订单，体现显著市场价值与客户认可度；
2. 数据处理时效性提升至秒级，全链路指标产出缩短至分钟级，大幅提升信息获取实时性；
3. 构建全链路指标报警监控与应急响应机制，降低日常维护成本，提升运维效率；
4. 通过K8S部署策略降低服务器扩容与部署成本，实现资源高效利用，节约成本20%。

### 项目四：营赛洞见大模型（大模型知识库）
**项目架构**：FastAPI+SSE+华为云DLI+ES+Langchain
**项目描述**：面向企业智能营销场景打造的一体化解决方案，融合大数据处理、AI大模型、多模态技术，包含模型工程、模型服务、知识库服务、场景管理4大模块；集成行业知识库、实时搜索增强、营销增强技术，为企业提供数据洞察、营销策略生成能力及简易操作界面。

**职责描述**：
1. 参与模型服务模块设计与开发，基于Langchain打通知识库、实时检索、Text2API等服务并上线维护；
2. 构建并优化知识库服务，通过多模态数据向量化技术实现数据与行业知识的高效关联检索，优化数据结构与查询算法；
3. 搭建模型风控体系，通过外部审核API+拒绝回答规则拦截风险查询；
4. 将RAG技术融入平台，结合检索与生成模型，提升文本生成的多样性与准确性；
5. 通过Text2API连通大模型与数据库，为企业提供高质量、高时效性的营销内容支撑。

**项目成果**：
1. 凭借严格的风控策略，模型顺利通过信通院评测并成功上线；
2. 构建行业首个面向营销领域的综合性大模型，填补市场空白；
3. 结合行业知识库与RAG技术，赋予模型实时检索与行业洞察能力，为企业提供深度市场理解。

### 项目五：大宇无限数据管理平台（数据平台）
**项目架构**：Athena+BigQuery+StarRocks+Flink+Hive+Superset
**项目描述**：为替换原有神策服务搭建的企业级数据中台，基于Kimball建模理论构建规范化数仓；通过Flink实现实时数据处理、Spark实现离线数据处理，StarRocks实时摄取Kafka数据生成实时指标；依托Hudi+S3构建数据湖，Athena实现数据湖查询，Superset搭建BI分析工具；基于AWS实现资源动态伸缩，支撑大规模数据处理与分析。

**职责描述**：
1. 基于Flink SQL实现日志数据接入ODS层，按存储时间做冷热温数据分层并采用差异化压缩，通过Spark合并小文件；
2. 负责事实数据处理，通过Flink实现事件表与维度表实时Join，保障数据精准一次性消费；
3. 搭建并优化StarRocks集群，开发高实时性指标，通过合理表设计+物化视图实现高并发、秒级查询；
4. 优化Spark离线数据处理，升级Spark至3.0并开启AQE实现任务自动优化，提升开发效率；
5. 基于Superset集成多数据源搭建BI平台，搭建广告领域数仓并产出上百个指标，为多部门提供高可靠数据服务。

**项目成果**：
1. 自研数据平台替换神策服务，为公司节省每年百万级服务成本；
2. 数据中台承载千万DAU用户的超百亿数据量，为运营、产品、算法等部门提供高可靠数据服务；
3. 显著提升用户查询速度，降低服务器机器使用与维护成本。

## 自我评价
1. 具备出色的沟通能力，可快速、准确捕捉业务方的需求与核心意图，高效推进需求落地；
2. 工作态度积极热情，乐于参与团队讨论，善于结合业务与技术提出建设性解决方案；
3. 对新技术、新挑战保持开放学习的心态，具备快速学习与技术落地的能力；
4. 工作严谨认真、责任心强，确保在规定时间内高质量完成各项工作任务；
5. 拥有良好的团队合作精神，可有效组织、协调团队资源，推动项目顺利落地执行。